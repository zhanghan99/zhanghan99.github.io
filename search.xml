<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ELK+Kafka</title>
      <link href="/2020/06/25/ELK-Kafka/"/>
      <url>/2020/06/25/ELK-Kafka/</url>
      
        <content type="html"><![CDATA[<h1 id="ELK-Kafka"><a href="#ELK-Kafka" class="headerlink" title="ELK+Kafka"></a>ELK+Kafka</h1><h3 id="利用ELK-Kafka解决方案，搭建企业级实时日志分析平台"><a href="#利用ELK-Kafka解决方案，搭建企业级实时日志分析平台" class="headerlink" title="利用ELK+Kafka解决方案，搭建企业级实时日志分析平台"></a>利用ELK+Kafka解决方案，搭建企业级实时日志分析平台</h3><blockquote><p>ELK 是三款软件的组合。是一整套完整的解决方案。分别是由 Logstash（收集+分析）、ElasticSearch（搜索+存储）、Kibana（可视化展示）三款软件。ELK主要是为了在海量的日志系统里面实现分布式日志数据集中式管理和查询，便于监控以及排查故障。</p></blockquote><hr><h4 id="准备DockerFile文件"><a href="#准备DockerFile文件" class="headerlink" title="准备DockerFile文件"></a>准备DockerFile文件</h4><p>1.修改ElasticSearch的DockerFile依赖的JDK镜像名</p><pre><code>    FROM jdk镜像名</code></pre><p>2.修改Kafka的DockerFile依赖的JDK镜像名,倒数第二行添加</p><pre><code>    FROM jdk镜像名</code></pre><pre><code>    EXPOSE 9092</code></pre><p>3.修改Kafka的Service.properties文件,改为你的虚拟机地址</p><pre><code>    advertised.listeners=PLAINTEXT://192.168.71.132:9092    zookeeper.connect=192.168.71.132:2181   </code></pre><p>4.修改Kibana的DockerFile依赖的JDK镜像名</p><pre><code>    FROM jdk镜像名</code></pre><p>5.修改Kibana.yml文件,改为你的虚拟机地址</p><pre><code>    elasticsearch.url: &quot;http://192.168.71.132:9200&quot;</code></pre><p>6.修改Kibana的DockerFile依赖的JDK镜像名</p><pre><code>    FROM jdk镜像名</code></pre><p>7.把logstash.conf文件中所有的IP地址改为你的</p><p>8.logstash.yml文件,IP地址</p><pre><code>    xpack.monitoring.elasticsearch.url: http://192.168.71.132:9200</code></pre><p>9.把ELK+Kafka文件夹拉入服务器</p><p>10.安装ElasticSearch镜像,创建容器</p><pre><code>    //执行DockerFile    docker build -t elasticsearch /home/kds/dockermv/Elasticsearch/    //创建容器    docker run -it -d -p 9200:9200 --name elasticsearch elasticsearch</code></pre><p>11.创建Kibana镜像,创建容器</p><pre><code>    //创建镜像    docker build -t kibana /home/kds/dockermv/Kibana/    //创建容器    docker run -it -d -p 5601:5601 --name kikana kikana</code></pre><p>12.创建Kafka镜像,创建容器</p><pre><code>    //创建镜像    docker build -t kafka /home/kds/dockermv/Kafka/    //创建容器    docker run -it -d -p 9092:9092 --name kafka kafka</code></pre><p>13.创建logstash</p><pre><code>    //创建镜像    docker build -t logstash /home/kds/dockermv/Logstash/    //创建容器    docker run -it -d -p logstash logstash</code></pre><hr><h3 id="ElasticSearch启动不成功"><a href="#ElasticSearch启动不成功" class="headerlink" title="ElasticSearch启动不成功"></a>ElasticSearch启动不成功</h3><ul><li><p>先限制性</p><pre><code>  sysctl -w vm.max_map_count=262144</code></pre></li><li><p>重启docker服务</p><pre><code>  systemctl  restart docker</code></pre></li><li><p>启动ElasticSearch容器</p></li></ul><h4 id="启动容器的步骤"><a href="#启动容器的步骤" class="headerlink" title="启动容器的步骤"></a>启动容器的步骤</h4><ul><li>先启动ElasticSearch</li><li></li><li>再启动Kibana</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ActivedMQ的简单应用</title>
      <link href="/2020/06/24/ActivedMQ%E7%9A%84%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8/"/>
      <url>/2020/06/24/ActivedMQ%E7%9A%84%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="ActiveMQ"><a href="#ActiveMQ" class="headerlink" title="ActiveMQ"></a>ActiveMQ</h1><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><blockquote><p>消息队列是在消息的传播过程中保存消息的容器<br><br><br><br>　<br>消息队列中间件是分布式系统中的重要组件,主要解决异步消息,应用解耦,流量削峰等问题,从而实现高性能,高可用,可伸缩和最终一致性的架构</p></blockquote><ul><li>异步请求</li><li>应用解耦</li><li>流量削峰</li></ul><hr><blockquote><p>Docker环境搭建</p></blockquote><p>通过Docker文件进行创建生成镜像文件<br></p><pre><code>docker build -t activemq/home/kds/dockermv/activeMQ5.15.2/</code></pre><p>创建容器<br></p><pre><code>docker run -it -d -p 8161:8161 -p 61616:61616 --name activemq activemq8161:HTTP协议61616:TCP协议</code></pre><hr><h3 id="ActiveMQ的简单应用"><a href="#ActiveMQ的简单应用" class="headerlink" title="ActiveMQ的简单应用"></a>ActiveMQ的简单应用</h3><p>1.创建发送者produce</p><p>2.导入SpringBoot整合ActiveMQ依赖</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>3.向yml文件中添加属性</p><pre><code>    spring:        activemq:            broker-url: tcp://192.168.71.131:61616            in-memory: true            pool:                enabled: false            packages:                trust-all: true</code></pre><p>4.创建controller</p><pre><code>@Resourceprivate JmsMessagingTemplate jmsMessagingTemplatel;@RequestMapping(&quot;/send&quot;)public String send(String message){    //创建队列的名称    Queue queue = new ActiveMQQueue(&quot;消息队列1&quot;);    //将消息发送到服务器中    jmsMessagingTemplatel.convertAndSend(queue,message);    return &quot;发送成功&quot;;}</code></pre><p>5.启动类添加注解,运行访问</p><pre><code>@EnableJms</code></pre><p>6.创建消费者Consumer,修改yml文件</p><pre><code>spring:    activemq:        broker-url: tcp://192.168.71.131:61616        in-memory: true        pool:            enabled: false        packages:            trust-all: trueserver:    port: 6666</code></pre><p>7.添加测试类</p><pre><code>@Componentpublic class Test {    @JmsListener(destination = &quot;消息队列2&quot;)    public void getMessage(String message){        System.out.println(message);    }}</code></pre><p>8.启动类添加注解,启动</p><pre><code>@EnableJms</code></pre><hr><h3 id="ActiveMQ参数信息"><a href="#ActiveMQ参数信息" class="headerlink" title="ActiveMQ参数信息"></a>ActiveMQ参数信息</h3><ul><li>Number Of Pending Messages     等待处理的消息有多少条</li><li>Number Of Consumers    有多少个消费者去处理消息</li><li>Messages Enqueued    进入队列的中的消息有多少条</li><li>Messages Dequeued    已处理的消息有多少条</li></ul><hr><h4 id="JMS消息模型P2P-Point-to-Point-点对点模式"><a href="#JMS消息模型P2P-Point-to-Point-点对点模式" class="headerlink" title="JMS消息模型P2P(Point to Point)点对点模式"></a>JMS消息模型P2P(Point to Point)点对点模式</h4><p>P2P模式包含三个角色:<br><br>   &nbsp; &nbsp;&nbsp;  消息队列(Queue),发送者(Sender),接收者(Receiver)</p><pre><code>Queue queue = new ActiveMQQueue(&quot;消息队列1&quot;);</code></pre><ul><li>每个消息只有一个消费者(Consumer)</li><li>发送者和接收者之间在时间上没有依赖性,也就是说当发送者发送了消息之后,不管接收者有没有正在运行,它不会影响到消息被发送到队列</li><li>接收者在成功接收消息之后需要想队列应答成功</li></ul><hr><h4 id="Publish-Subscribe-Pub-Sub-发布订阅模式"><a href="#Publish-Subscribe-Pub-Sub-发布订阅模式" class="headerlink" title="Publish/Subscribe(Pub/Sub)发布订阅模式"></a>Publish/Subscribe(Pub/Sub)发布订阅模式</h4><p>Pbu/Sub模式包含三个角色:<br><br>    &nbsp; &nbsp;&nbsp;<br>    主题(Topic),发布者(Publisher),订阅者(Receiver)</p><pre><code>Topic topic = new ActiveMQTopic(&quot;订阅队列&quot;);//配置消息中间件的模式  false 点对点模式   true 发布订阅模式//发布者消费者需要配置jms:     pub-sub-domain: true</code></pre><ul><li>每个消息可以有多个消费者</li><li>发布者和订阅者之间有时间上的依赖性.针对某个主题的订阅者,他必须创建一个订阅之后,才能消费发布者的消息</li><li>为了消费消息,订阅者必须保持运行的状态</li></ul>]]></content>
      
      
      <categories>
          
          <category> Markdown </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
