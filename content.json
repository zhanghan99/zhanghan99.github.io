{"meta":{"title":"Xiao ocean","subtitle":"每天进步,每天进步","description":"","author":"Xiao ocean","url":"http://yoursite.com","root":"/"},"pages":[{"title":"about","date":"2020-06-25T07:03:40.000Z","updated":"2020-06-25T07:03:50.537Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-06-25T07:02:08.000Z","updated":"2020-06-25T07:02:39.756Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-06-25T07:02:51.000Z","updated":"2020-06-25T07:03:10.143Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"ELK+Kafka","slug":"ELK-Kafka","date":"2020-06-25T03:40:03.000Z","updated":"2020-06-25T03:41:38.961Z","comments":true,"path":"2020/06/25/ELK-Kafka/","link":"","permalink":"http://yoursite.com/2020/06/25/ELK-Kafka/","excerpt":"","text":"ELK+Kafka利用ELK+Kafka解决方案，搭建企业级实时日志分析平台 ELK 是三款软件的组合。是一整套完整的解决方案。分别是由 Logstash（收集+分析）、ElasticSearch（搜索+存储）、Kibana（可视化展示）三款软件。ELK主要是为了在海量的日志系统里面实现分布式日志数据集中式管理和查询，便于监控以及排查故障。 准备DockerFile文件1.修改ElasticSearch的DockerFile依赖的JDK镜像名 FROM jdk镜像名2.修改Kafka的DockerFile依赖的JDK镜像名,倒数第二行添加 FROM jdk镜像名 EXPOSE 90923.修改Kafka的Service.properties文件,改为你的虚拟机地址 advertised.listeners=PLAINTEXT://192.168.71.132:9092 zookeeper.connect=192.168.71.132:2181 4.修改Kibana的DockerFile依赖的JDK镜像名 FROM jdk镜像名5.修改Kibana.yml文件,改为你的虚拟机地址 elasticsearch.url: &quot;http://192.168.71.132:9200&quot;6.修改Kibana的DockerFile依赖的JDK镜像名 FROM jdk镜像名7.把logstash.conf文件中所有的IP地址改为你的 8.logstash.yml文件,IP地址 xpack.monitoring.elasticsearch.url: http://192.168.71.132:92009.把ELK+Kafka文件夹拉入服务器 10.安装ElasticSearch镜像,创建容器 //执行DockerFile docker build -t elasticsearch /home/kds/dockermv/Elasticsearch/ //创建容器 docker run -it -d -p 9200:9200 --name elasticsearch elasticsearch11.创建Kibana镜像,创建容器 //创建镜像 docker build -t kibana /home/kds/dockermv/Kibana/ //创建容器 docker run -it -d -p 5601:5601 --name kikana kikana12.创建Kafka镜像,创建容器 //创建镜像 docker build -t kafka /home/kds/dockermv/Kafka/ //创建容器 docker run -it -d -p 9092:9092 --name kafka kafka13.创建logstash //创建镜像 docker build -t logstash /home/kds/dockermv/Logstash/ //创建容器 docker run -it -d -p logstash logstash ElasticSearch启动不成功 先限制性 sysctl -w vm.max_map_count=262144 重启docker服务 systemctl restart docker 启动ElasticSearch容器 启动容器的步骤 先启动ElasticSearch 再启动Kibana","categories":[],"tags":[]},{"title":"ActivedMQ的简单应用","slug":"ActivedMQ的简单应用","date":"2020-06-24T09:53:51.000Z","updated":"2020-06-24T09:54:20.112Z","comments":true,"path":"2020/06/24/ActivedMQ的简单应用/","link":"","permalink":"http://yoursite.com/2020/06/24/ActivedMQ%E7%9A%84%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8/","excerpt":"","text":"ActiveMQ应用场景 消息队列是在消息的传播过程中保存消息的容器 消息队列中间件是分布式系统中的重要组件,主要解决异步消息,应用解耦,流量削峰等问题,从而实现高性能,高可用,可伸缩和最终一致性的架构 异步请求 应用解耦 流量削峰 Docker环境搭建 通过Docker文件进行创建生成镜像文件 docker build -t activemq/home/kds/dockermv/activeMQ5.15.2/创建容器 docker run -it -d -p 8161:8161 -p 61616:61616 --name activemq activemq 8161:HTTP协议 61616:TCP协议 ActiveMQ的简单应用1.创建发送者produce 2.导入SpringBoot整合ActiveMQ依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt; &lt;/dependency&gt;3.向yml文件中添加属性 spring: activemq: broker-url: tcp://192.168.71.131:61616 in-memory: true pool: enabled: false packages: trust-all: true4.创建controller @Resource private JmsMessagingTemplate jmsMessagingTemplatel; @RequestMapping(&quot;/send&quot;) public String send(String message){ //创建队列的名称 Queue queue = new ActiveMQQueue(&quot;消息队列1&quot;); //将消息发送到服务器中 jmsMessagingTemplatel.convertAndSend(queue,message); return &quot;发送成功&quot;; }5.启动类添加注解,运行访问 @EnableJms6.创建消费者Consumer,修改yml文件 spring: activemq: broker-url: tcp://192.168.71.131:61616 in-memory: true pool: enabled: false packages: trust-all: true server: port: 66667.添加测试类 @Component public class Test { @JmsListener(destination = &quot;消息队列2&quot;) public void getMessage(String message){ System.out.println(message); } }8.启动类添加注解,启动 @EnableJms ActiveMQ参数信息 Number Of Pending Messages 等待处理的消息有多少条 Number Of Consumers 有多少个消费者去处理消息 Messages Enqueued 进入队列的中的消息有多少条 Messages Dequeued 已处理的消息有多少条 JMS消息模型P2P(Point to Point)点对点模式P2P模式包含三个角色: &nbsp; &nbsp;&nbsp; 消息队列(Queue),发送者(Sender),接收者(Receiver) Queue queue = new ActiveMQQueue(&quot;消息队列1&quot;); 每个消息只有一个消费者(Consumer) 发送者和接收者之间在时间上没有依赖性,也就是说当发送者发送了消息之后,不管接收者有没有正在运行,它不会影响到消息被发送到队列 接收者在成功接收消息之后需要想队列应答成功 Publish/Subscribe(Pub/Sub)发布订阅模式Pbu/Sub模式包含三个角色: &nbsp; &nbsp;&nbsp; 主题(Topic),发布者(Publisher),订阅者(Receiver) Topic topic = new ActiveMQTopic(&quot;订阅队列&quot;); //配置消息中间件的模式 false 点对点模式 true 发布订阅模式 //发布者消费者需要配置 jms: pub-sub-domain: true 每个消息可以有多个消费者 发布者和订阅者之间有时间上的依赖性.针对某个主题的订阅者,他必须创建一个订阅之后,才能消费发布者的消息 为了消费消息,订阅者必须保持运行的状态","categories":[],"tags":[]}],"categories":[],"tags":[]}